# ğŸ¤– CLI Chatbot with TinyLlama and LangChain

This project demonstrates a simple command-line chatbot interface built using the **TinyLlama** model with **LangChain** components, executed in **Google Colab**.

---

## ğŸ“Œ Features

- ğŸ§  Uses TinyLlama language model from Hugging Face
- ğŸ’¬ Maintains conversational memory using a circular buffer
- ğŸ› ï¸ Modular design with clear class responsibilities
- âœ… Runs interactively in Google Colab

---

## ğŸ§± Code Structure

### ğŸ“ Classes

| Class        | Responsibility                                |
|--------------|-----------------------------------------------|
| `ModelLoader`| Loads and initializes the TinyLlama model     |
| `ChatMemory` | Stores and retrieves chat history             |
| `Chatbot`    | Main interface handling the chatbot loop      |

---

## ğŸ”‘ Key Methods

- **`ModelLoader.load()`**: Downloads and returns the model and tokenizer  
- **`ChatMemory.add(user_input, bot_response)`**: Adds conversation turns  
- **`ChatMemory.get_context()`**: Returns formatted chat history  
- **`Chatbot.run()`**: Starts the interactive chatbot loop

---

## ğŸš€ Getting Started in Google Colab

### 1ï¸âƒ£ Open a new Colab Notebook  
Go to [Google Colab](https://colab.research.google.com/) and start a new Python 3 notebook.

### 2ï¸âƒ£ Install Required Dependencies

Paste the following in the first cell and run it:

```python
!pip install transformers torch
